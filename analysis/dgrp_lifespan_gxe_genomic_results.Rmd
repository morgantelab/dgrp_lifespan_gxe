---
title: "Genomic prediction of life span with different models"
author: "Fabio Morgante"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output: 
  workflowr::wflow_html:
    toc: true
editor_options:
  chunk_output_type: console
---

```{r set options, message=FALSE}
###Load libraries
library(ggplot2)
library(cowplot)
library(tidyr)
library(dplyr)

prefix <- "dgrp_lifespan_gxe"
reps <- c(1,2,4,5,7,9)
```

## Introduction

The goal of this analysis is to assess the performance of the linear mixed models including genotype only, environment only,
genotype + environment, genotype + environment + genotype $\times$ environment information at predicting life span in the 
DGRP.

We used data from [Huang et al. (2020)](https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.3000645), which
has life span measurements for $n=176$ lines at 3 temperatures (18C, 25C, 28C) for the 2 sexes (coded as 1=females and 0=males), 
which results in $q=1,056$ observations. 
The authors showed that there is extensive $G \times E$ affecting life span. In the present work, we used both temperature 
and sex as $c=2$ environmental variables, for a total of $r=6$ environments.

We fitted the following linear mixed models:

* G-BLUP -- $y = \mu + g + \epsilon$.
* E-BLUP -- $y = \mu + e + \epsilon$.
* GE-BLUP -- $y = \mu + g + e + \epsilon$.
* GxE-BLUP -- $y = \mu + g + e + ge + \epsilon$.

where

$y$ is a $q$-vector of phenotypic observations, 
$\mu$ is a $q$-vector of intercept values, 
$g$ is a $q$-vector of additive genetic values, $g \sim N_q(\mathbf O, \mathbf{ZGZ^\intercal} \sigma^2_g)$, 
$\mathbf Z$ is a $q \times n$ incidence matrix, 
$\mathbf G$ is a $n \times n$ genomic relationship matrix (GRM), 
$e$ is a $q$-vector of environmental values, $e \sim N_q(\mathbf O, \mathbf{E} \sigma^2_e)$, 
$\mathbf E$ is a $q \times q$  matrix of similarity based on environmental variables, computed as 
$\mathbf E = \mathbf{XX}^\intercal$, 
$\mathbf X$ is a $q \times c$ matrix of environmental measurements,
$ge \sim N_q(\mathbf O, \mathbf{ZGZ^\intercal \circ E} \sigma^2_{ge})$,
$\epsilon$ is a $q$-vector of residual values, $\epsilon \sim N_q(\mathbf O, \mathbf{I} \sigma^2_\epsilon)$.

These models were also implemented with heterogeneous residual variances across environments.

We also fit a multivariate GBLUP -- $Y = M + U + R$:

where

$Y$ is an $n \times r$ matrix of phenotypic observations, 
$M$ is an $r$-vector of intercept values, 
$U$ is an $n \times r$ matrix of additive genetic values, $U \sim MN_{n \times r} (\mathbf O, \mathbf G, \mathbf \Sigma_U)$ and $\mathbf \Sigma_U$ is an $r \times r$ covariance matrix,
$R$ is an $r \times r$ matrix of residual values, $R \sim MN_{n \times r} (\mathbf O, \mathbf I_n, \mathbf \Sigma_R)$ and $\mathbf  \Sigma_R$ is an $r \times r$ covariance matrix.

We also fit a random regression model -- $y_{is} = \sum_{m=0}^K \beta_{m} \phi_m(s) + \sum_{m=0}^K a_{im} \phi_m(s) + \epsilon$:

where

$y_{is}$ is the phenotype for line $i$ in environment $s$, 
$\phi_m(s)$ is the Legendre polynomial of order $m$ for environment $s$,
$\beta_{m}$ is the fixed effect of the $m^{th}$-order Legendre polynomial,
$a_{im}$ is the random additive genetic value of the $m^{th}$-order Legendre polynomial, $a_{im} \sim N(\mathbf 0, \mathbf G \otimes \mathbf \Sigma_a)$ and $\mathbf  \Sigma_r$ is an $K \times K$ covariance matrix.
$\epsilon_{is}$ is the residual value for line $i$ in environment $s$, $\epsilon \sim N(O, \sigma^2_{\epsilon s})$.

After some testing, we chose $K=1$.

All these models (except for the random regression) were fitted in the training set using a Bayesian approach as implemented in the 
$\sf BGLR$ package. The random regression model was fitted in the training set using a REML approach as implemented in the 
$\sf sommer$ package.

We used different cross-validation schemes:

* _Random within environment scenario_. We assigned 17\% of the *lines* to the test set randomly and analyzed each sex/temperature 
combination separately using the standard GBLUP model. This procedure was repeated 6 times.
* _Random lines scenario_. We assigned 17\% of the *lines* (i.e., for the 2 sexes and the 3 temperatures) to the test set randomly, 
and analyzed the sex/temperature combinations jointly with the models above. The peculiarity of this scenario is that the lines in 
the test set are not represented at all in the training set. This procedure was repeated 6 times.
* _Random observations scenario_. We assigned 17\% of the *observations* (i.e., combination of line, sex and temperature) to 
the test set randomly, and analyzed the sex/temperature combinations jointly with the models above. The peculiarity of this 
scenario is that all the lines, sexes and temperatures are represented in the training set. This procedure was repeated 6 times.
* _New temperature and sex scenario_. We assigned all the observations in a specific temperature and sex to the test set, i.e., that combination 
is never seen in the training set. This procedure was repeated 6 times, once for each temperature/sex combination.

Prediction accuracy was evaluated as the $R^2$ of the regression of observed phenotypes on predicted phenotypes in the test set.

## Results

### Random within environment scenario

This is the baseline scenario, where we acknowldege that the genetic architecture of life span is different across environments and we
analyze them separately using G-BLUP.

```{r random within env orig, fig.height=10, fig.width=13}
sex <- c(1, 0)
temp <- c(18,25,28)
model <- "G"
pheno <- "original_pheno"


i <- 0

n_col <- 6
n_row <- length(reps) * length(sex) * length(temp) * length(model)
res <- as.data.frame(matrix(NA, ncol=n_col, nrow=n_row))
colnames(res) <- c("rep", "sex", "temp", "model", "r2", "env")

res_var <- as.data.frame(matrix(NA, ncol=n_col+2, nrow=n_row))
colnames(res_var) <- c("rep", "sex", "temp", "model", "VarG", "VarEps", "H2", "env")


for(s in sex){
  for(t in temp){
    for(repp in reps){
      dat <- readRDS(paste0("output/G_fit/", prefix, "_", pheno, "_random_within_env_", s, "_", t, "_G_fit_", repp, ".rds"))
      i <- i + 1
      
      res[i, 1] <- repp
      res[i, 2] <- s
      res[i, 3] <- t
      res[i, 4] <- model
      res[i, 5] <- summary(lm(dat$y_test ~ dat$yhat_test))$r.squared
      res[i, 6] <- paste0(s, "_", t)
      
      res_var[i, 1] <- repp
      res_var[i, 2] <- s
      res_var[i, 3] <- t
      res_var[i, 4] <- model
      res_var[i, 5] <- dat$model_fit$ETA$G$varU
      res_var[i, 6] <- dat$model_fit$varE
      res_var[i, 7] <- dat$model_fit$ETA$G$varU/(dat$model_fit$ETA$G$varU + dat$model_fit$varE)
      res_var[i, 8] <- paste0(s, "_", t)

    }
  }
}

#res_var_long <- res_var %>% select(rep, VarG, VarEps, env) %>% gather(value="Var", key="Source", VarG, VarEps)
res_var <- transform(res_var, env=as.factor(env))

p_var <- ggplot(res_var, aes(x = env, y = H2)) +
  geom_boxplot(color = "black", outlier.size = 1, width = 0.85) +
  stat_summary(fun=mean, geom="point", shape=23,
               position = position_dodge2(width = 0.87,   
                                          preserve = "single")) +
  labs(x = "Environment", y = expression(italic(PVE)), title="") +
  theme_cowplot(font_size = 18)

print(p_var)



res <- transform(res, env=as.factor(env))

p <- ggplot(res, aes(x = env, y = r2)) +
  geom_boxplot(color = "black", outlier.size = 1, width = 0.85) +
  stat_summary(fun=mean, geom="point", shape=23,
               position = position_dodge2(width = 0.87,   
                                          preserve = "single")) +
  labs(x = "Environment", y = expression(italic(R)^2), title="") +
  theme_cowplot(font_size = 18)

print(p)

res %>% group_by(env) %>% summarise(mean_r2=mean(r2), se_r2=(sd(r2)/length(reps))) %>% as.data.frame()
```

The results show that prediction accuracy varies across environments and is generally low. As expected, scaling the phenotypes does
not affect accuracy in this case.



### Random lines scenario

In this scenario, we combine the data across environments and fit the different models.

```{r random lines orig het, fig.height=10, fig.width=13}
schemes <- "random_lines"
model <- c('G_het_var','E_het_var','GandE_het_var','GxE_het_var','mvgblup','rrm')
pheno <- "original_pheno"

i <- 0

n_col <- 4
n_row <- length(reps) * length(schemes) * length(model)
res <- as.data.frame(matrix(NA, ncol=n_col, nrow=n_row))
colnames(res) <- c("rep", "scheme", "model", "r2")

for(sche in schemes){
  for(met in model){
    for(repp in reps){
      dat <- readRDS(paste0("output/", met, "_fit/", prefix, "_", pheno, "_", sche, "_", met, "_fit_", repp, ".rds"))
      i <- i + 1
        
      res[i, 1] <- repp
      res[i, 2] <- sche
      res[i, 3] <- met
      if(met == "mvgblup"){
        y_test <- do.call("c", dat$y_test)
        yhat_test <- do.call("c", dat$yhat_test)
        res[i, 4] <- summary(lm(y_test ~ yhat_test))$r.squared
      } else {
        res[i, 4] <- summary(lm(dat$y_test ~ dat$yhat_test))$r.squared
      }
    }
  }
}


###Accuracy
res <- transform(res, scheme=as.factor(scheme),
                 model=as.factor(model))

p <- ggplot(res, aes(x = model, y = r2, fill = model)) +
  geom_boxplot(color = "black", outlier.size = 1, width = 0.85) +
  stat_summary(fun=mean, geom="point", shape=23,
               position = position_dodge2(width = 0.87,   
                                          preserve = "single")) +
  scale_fill_manual(values = c("pink", "red", "yellow", "orange", "green", "blue", "lightblue")) +
  labs(x = "Model", y = expression(italic(R)^2), fill="Method", title="") +
  theme_cowplot(font_size = 18) +
  theme(legend.position="none")

print(p)

res %>% group_by(model) %>% summarise(mean_r2=mean(r2), se_r=(sd(r2)/length(reps))) %>% as.data.frame()
```

The results show that G-BLUP performs poorly. 
This is expected because we are making the implicit assumption that genetic effects are equal across environments, which 
is not the case. E-BLUP does very well in this scenario because when combining the data across environments, a lot of the 
variance is explained by the environmental effects, which we have good power to estimate. GE-BLUP, GxE-BLUP, and mvG-BLUP give very 
similar accuracy to E-BLUP. This is not surprising since some lines are not in the training set, so the training-test 
transfer of information happens mostly at the environment level. RRM does intermediately between G-BLUP and the other models. 


#### GxE by chromosomes models

```{r random lines orig het chr, fig.height=10, fig.width=13}
schemes <- "random_lines"
model <- c('GxE_het_var', 'GxE_by_chr_het_var')
pheno <- "original_pheno"

i <- 0

n_col <- 4
n_row <- length(reps) * length(schemes) * length(model)
res <- as.data.frame(matrix(NA, ncol=n_col, nrow=n_row))
colnames(res) <- c("rep", "scheme", "model", "r2")

for(sche in schemes){
  for(met in model){
    for(repp in reps){
      dat <- readRDS(paste0("output/", met, "_fit/", prefix, "_", pheno, "_", sche, "_", met, "_fit_", repp, ".rds"))
      i <- i + 1
        
      res[i, 1] <- repp
      res[i, 2] <- sche
      res[i, 3] <- met
      res[i, 4] <- summary(lm(dat$y_test ~ dat$yhat_test))$r.squared
    }
  }
}


###Accuracy
res <- transform(res, scheme=as.factor(scheme),
                 model=factor(model, levels = c('GxE_het_var', 'GxE_by_chr_het_var')))

p <- ggplot(res, aes(x = model, y = r2, fill = model)) +
  geom_boxplot(color = "black", outlier.size = 1, width = 0.85) +
  stat_summary(fun=mean, geom="point", shape=23,
               position = position_dodge2(width = 0.87,   
                                          preserve = "single")) +
  scale_fill_manual(values = c("pink", "red", "yellow", "orange", "green", "blue", "lightblue")) +
  labs(x = "Model", y = expression(italic(R)^2), fill="Method", title="") +
  theme_cowplot(font_size = 18) +
  theme(legend.position="none")

print(p)

res %>% group_by(model) %>% summarise(mean_r2=mean(r2), se_r=(sd(r2)/length(reps))) %>% as.data.frame()
```

Splitting the GxE component across chromosomes provides similar results to the standard GxE-BLUP results.


### Random observations scenario

In this scenario, every line and environment is potentially represented in the training set. It is specific combinations of
lines and environments (e.g., line_101 in females at 18C) that are not seen in the training set. This is the scenario 
where we expect an advantage from using models with both genotype and environment information because the training-test 
transfer of information happens at every level.

```{r random obs orig het, fig.height=10, fig.width=13}
schemes <- "random_obs"
model <- c('G_het_var','E_het_var','GandE_het_var','GxE_het_var','mvgblup','rrm')
pheno <- "original_pheno"

i <- 0

n_col <- 4
n_row <- length(reps) * length(schemes) * length(model)
res <- as.data.frame(matrix(NA, ncol=n_col, nrow=n_row))
colnames(res) <- c("rep", "scheme", "model", "r2")

for(sche in schemes){
  for(met in model){
    for(repp in reps){
      dat <- readRDS(paste0("output/", met, "_fit/", prefix, "_", pheno, "_", sche, "_", met, "_fit_", repp, ".rds"))
      i <- i + 1
        
      res[i, 1] <- repp
      res[i, 2] <- sche
      res[i, 3] <- met
      if(met == "mvgblup"){
        y_test <- do.call("c", dat$y_test)
        yhat_test <- do.call("c", dat$yhat_test)
        res[i, 4] <- summary(lm(y_test ~ yhat_test))$r.squared
      } else {
        res[i, 4] <- summary(lm(dat$y_test ~ dat$yhat_test))$r.squared
      }
    }
  }
}


###Accuracy
res <- transform(res, scheme=as.factor(scheme),
                 model=as.factor(model))

p <- ggplot(res, aes(x = model, y = r2, fill = model)) +
  geom_boxplot(color = "black", outlier.size = 1, width = 0.85) +
  stat_summary(fun=mean, geom="point", shape=23,
               position = position_dodge2(width = 0.87,   
                                          preserve = "single")) +
  scale_fill_manual(values = c("pink", "red", "yellow", "orange", "green", "blue", "lightblue")) +
  labs(x = "Model", y = expression(italic(R)^2), fill="Method", title="") +
  theme_cowplot(font_size = 18) +
  theme(legend.position="none")

print(p)

res %>% group_by(model) %>% summarise(mean_r2=mean(r2), se_r=(sd(r2)/length(reps))) %>% as.data.frame()
```

The results show that, as expected, GE-BLUP improves prediction accuracy over E-BLUP and GxE-BLUP achieves higher prediction accuracy
than GE-BLUP. mvG-BLUP achieves the highest accuracy as it can leverage the strong genetic correlations among some environments, while also
accounting for genetic and environmental differences. RRM does intermediately between G-BLUP and the other models.


#### GxE by chromosomes models

```{r random obs orig het chr, fig.height=10, fig.width=13}
schemes <- "random_obs"
model <- c('GxE_het_var', 'GxE_by_chr_het_var')
pheno <- "original_pheno"

i <- 0

n_col <- 4
n_row <- length(reps) * length(schemes) * length(model)
res <- as.data.frame(matrix(NA, ncol=n_col, nrow=n_row))
colnames(res) <- c("rep", "scheme", "model", "r2")

for(sche in schemes){
  for(met in model){
    for(repp in reps){
      dat <- readRDS(paste0("output/", met, "_fit/", prefix, "_", pheno, "_", sche, "_", met, "_fit_", repp, ".rds"))
      i <- i + 1
        
      res[i, 1] <- repp
      res[i, 2] <- sche
      res[i, 3] <- met
      res[i, 4] <- summary(lm(dat$y_test ~ dat$yhat_test))$r.squared
    }
  }
}


###Accuracy
res <- transform(res, scheme=as.factor(scheme),
                 model=factor(model, levels = c('GxE_het_var', 'GxE_by_chr_het_var')))

p <- ggplot(res, aes(x = model, y = r2, fill = model)) +
  geom_boxplot(color = "black", outlier.size = 1, width = 0.85) +
  stat_summary(fun=mean, geom="point", shape=23,
               position = position_dodge2(width = 0.87,   
                                          preserve = "single")) +
  scale_fill_manual(values = c("pink", "red", "yellow", "orange", "green", "blue", "lightblue")) +
  labs(x = "Model", y = expression(italic(R)^2), fill="Method", title="") +
  theme_cowplot(font_size = 18) +
  theme(legend.position="none")

print(p)

res %>% group_by(model) %>% summarise(mean_r2=mean(r2), se_r=(sd(r2)/length(reps))) %>% as.data.frame()
```

Splitting the GxE component across chromosomes provides slightly better results than the standard GxE-BLUP results.


### New temperature and sex scenario

In this scenario, we assigned all the observations in a specific temperature and sex to the test set, i.e., that temperature/sex 
combination is never seen in the training set.

```{r across temp/sex orig het, fig.height=10, fig.width=13}
n_reps <- 6
schemes <- "temp_sex"
model <- c('G_het_var','E_het_var','GandE_het_var','GxE_het_var','rrm')
pheno <- "original_pheno"

i <- 0

n_col <- 4
n_row <- n_reps * length(schemes) * length(model)
res <- as.data.frame(matrix(NA, ncol=n_col, nrow=n_row))
colnames(res) <- c("rep", "scheme", "model", "r2")

for(sche in schemes){
  for(met in model){
    for(repp in 1:n_reps){
      dat <- readRDS(paste0("output/", met, "_fit/", prefix, "_", pheno, "_", sche, "_", met, "_fit_", repp, ".rds"))
      i <- i + 1
        
      res[i, 1] <- repp
      res[i, 2] <- sche
      res[i, 3] <- met
      res[i, 4] <- summary(lm(dat$y_test ~ dat$yhat_test))$r.squared
    }
  }
}


###Accuracy
res <- transform(res, scheme=as.factor(scheme),
                 model=as.factor(model))

p <- ggplot(res, aes(x = model, y = r2, fill = model)) +
  geom_boxplot(color = "black", outlier.size = 1, width = 0.85) +
  stat_summary(fun=mean, geom="point", shape=23,
               position = position_dodge2(width = 0.87,   
                                          preserve = "single")) +
  scale_fill_manual(values = c("pink", "red", "yellow", "orange", "green", "blue", "lightblue")) +
  labs(x = "Model", y = expression(italic(R)^2), fill="Method", title="") +
  theme_cowplot(font_size = 18) +
  theme(legend.position="none")

print(p)

res %>% group_by(model) %>% summarise(mean_r2=mean(r2), se_r=(sd(r2)/n_reps)) %>% as.data.frame()
```

In general, prediction accuracy is lower in this scenario. As expected, E-BLUP does not have any predictive ability; all the observations
in the test set get the same predicted phenotype because they are equally "related" based on the environment. G-BLUP predicts decently
because all the lines are present in the test set. GE-BLUP improves accuracy over G-BLUP because observations are now stratified by both
genetics and environment. GxE-BLUP does better than GE-BLUP because it can capture the difference in genetic effects across environments
and "extrapolate" to a new environment better. RMM is now competitive with GE-BLUP, although it produces a more variable performance.


#### GxE by chromosomes models

```{r across temp/sex orig het chr, fig.height=10, fig.width=13}
schemes <- "temp_sex"
model <- c('GxE_het_var', 'GxE_by_chr_het_var')
pheno <- "original_pheno"

i <- 0

n_col <- 4
n_row <- n_reps * length(schemes) * length(model)
res <- as.data.frame(matrix(NA, ncol=n_col, nrow=n_row))
colnames(res) <- c("rep", "scheme", "model", "r2")

for(sche in schemes){
  for(met in model){
    for(repp in 1:n_reps){
      dat <- readRDS(paste0("output/", met, "_fit/", prefix, "_", pheno, "_", sche, "_", met, "_fit_", repp, ".rds"))
      i <- i + 1
        
      res[i, 1] <- repp
      res[i, 2] <- sche
      res[i, 3] <- met
      res[i, 4] <- summary(lm(dat$y_test ~ dat$yhat_test))$r.squared
    }
  }
}


###Accuracy
res <- transform(res, scheme=as.factor(scheme),
                 model=factor(model, levels = c('GxE_het_var', 'GxE_by_chr_het_var')))

p <- ggplot(res, aes(x = model, y = r2, fill = model)) +
  geom_boxplot(color = "black", outlier.size = 1, width = 0.85) +
  stat_summary(fun=mean, geom="point", shape=23,
               position = position_dodge2(width = 0.87,   
                                          preserve = "single")) +
  scale_fill_manual(values = c("pink", "red", "yellow", "orange", "green", "blue", "lightblue")) +
  labs(x = "Model", y = expression(italic(R)^2), fill="Method", title="") +
  theme_cowplot(font_size = 18) +
  theme(legend.position="none")

print(p)

res %>% group_by(model) %>% summarise(mean_r2=mean(r2), se_r=(sd(r2)/n_reps)) %>% as.data.frame()
```

Splitting the GxE component across chromosomes provides worse results than the standard GxE-BLUP results.
...